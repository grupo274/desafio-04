#!/bin/bash

echo "ğŸ³ Iniciando container com Ollama + CrewAI..."

# FunÃ§Ã£o para cleanup ao sair
cleanup() {
    echo "ğŸ§¹ Finalizando processos..."
    pkill -f ollama || true
    exit 0
}
trap cleanup SIGTERM SIGINT

# FunÃ§Ã£o para verificar se Ollama estÃ¡ rodando
check_ollama() {
    curl -s http://localhost:11434/api/version > /dev/null 2>&1
    return $?
}

# 1. Iniciar Ollama em background
echo "ğŸš€ Iniciando Ollama server..."
ollama serve > /tmp/ollama.log 2>&1 &
OLLAMA_PID=$!

# 2. Aguardar Ollama ficar disponÃ­vel
echo "â³ Aguardando Ollama inicializar..."
for i in {1..60}; do
    if check_ollama; then
        echo "âœ… Ollama rodando na porta 11434"
        break
    fi
    sleep 2
    if [ $i -eq 60 ]; then
        echo "âŒ Timeout: Ollama nÃ£o iniciou em 2 minutos"
        echo "ğŸ“‹ Log do Ollama:"
        cat /tmp/ollama.log
        exit 1
    fi
    echo "   Tentativa $i/60..."
done

# 3. Verificar se temos modelos, senÃ£o baixar um pequeno
echo "ğŸ” Verificando modelos disponÃ­veis..."
MODELS=$(ollama list 2>/dev/null | grep -v "NAME" | wc -l)

if [ "$MODELS" -eq 0 ]; then
    echo "ğŸ“¥ Nenhum modelo encontrado. Baixando modelo pequeno..."
    echo "   Isso pode levar alguns minutos na primeira execuÃ§Ã£o..."
    
    # Tentar modelos em ordem de preferÃªncia (menor para maior)
    for model in "llama3.2:1b" "llama3.2" "mistral:7b" "llama3.1:8b"; do
        echo "ğŸ”„ Tentando baixar $model..."
        if timeout 300 ollama pull $model; then
            echo "âœ… Modelo $model baixado com sucesso!"
            break
        else
            echo "âŒ Falha ao baixar $model, tentando prÃ³ximo..."
        fi
    done
    
    # Verificar se conseguiu baixar algum modelo
    NEW_MODELS=$(ollama list 2>/dev/null | grep -v "NAME" | wc -l)
    if [ "$NEW_MODELS" -eq 0 ]; then
        echo "âš ï¸ NÃ£o foi possÃ­vel baixar nenhum modelo"
        echo "ğŸ­ A aplicaÃ§Ã£o usarÃ¡ Mock LLM"
    fi
else
    echo "âœ… Encontrados $MODELS modelo(s) jÃ¡ instalado(s)"
fi

# 4. Mostrar status atual
echo ""
echo "ğŸ“Š Status do sistema:"
echo "   Ollama PID: $OLLAMA_PID"
echo "   Status: $(check_ollama && echo 'ğŸŸ¢ Rodando' || echo 'ğŸ”´ Parado')"
echo "   Modelos disponÃ­veis:"
ollama list 2>/dev/null || echo "   (Nenhum modelo listado)"
echo ""

# 5. Executar a aplicaÃ§Ã£o
echo "ğŸš€ Executando aplicaÃ§Ã£o CrewAI..."
python main.py

# 6. Se a aplicaÃ§Ã£o terminou, mostrar opÃ§Ãµes
echo ""
echo "ğŸ“‹ AplicaÃ§Ã£o finalizada."
echo "ğŸ”§ Para debug, conecte no container:"
echo "   docker exec -it \$(docker ps -q) /bin/bash"
echo ""
echo "ğŸ”„ Para executar novamente:"
echo "   python main.py"
echo ""

# 7. Manter container ativo para investigaÃ§Ã£o
echo "â¸ï¸ Container ficarÃ¡ ativo. Pressione Ctrl+C para sair."
wait