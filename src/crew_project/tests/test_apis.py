#!/usr/bin/env python3
"""
Script para testar API Keys dos diferentes provedores LLM
"""
import os
import sys
from dotenv import load_dotenv

# Carregar vari√°veis de ambiente
load_dotenv()

def test_openai_key():
    """Testa a API Key do OpenAI."""
    try:
        from openai import OpenAI
        
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("‚ùå OPENAI_API_KEY n√£o encontrada no .env")
            return False
            
        print(f"üîë Testando OpenAI key: {api_key[:10]}...")
        
        client = OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": "Hello"}],
            max_tokens=5
        )
        
        print("‚úÖ OpenAI key v√°lida!")
        return True
        
    except Exception as e:
        print(f"‚ùå Erro OpenAI: {e}")
        return False


def test_groq_key():
    """Testa a API Key do Groq."""
    try:
        import requests
        
        api_key = os.getenv("GROQ_API_KEY")
        if not api_key:
            print("‚ùå GROQ_API_KEY n√£o encontrada no .env")
            return False
            
        print(f"üîë Testando Groq key: {api_key[:10]}...")
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "messages": [{"role": "user", "content": "Hello"}],
            "model": "mixtral-8x7b-32768",
            "max_tokens": 5
        }
        
        response = requests.post(
            "https://api.groq.com/openai/v1/chat/completions",
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            print("‚úÖ Groq key v√°lida!")
            return True
        else:
            print(f"‚ùå Groq erro {response.status_code}: {response.text}")
            return False
            
    except Exception as e:
        print(f"‚ùå Erro Groq: {e}")
        return False


def test_gemini_key():
    """Testa a API Key do Google Gemini."""
    try:
        import google.generativeai as genai
        
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            print("‚ùå GOOGLE_API_KEY n√£o encontrada no .env")
            return False
            
        print(f"üîë Testando Gemini key: {api_key[:10]}...")
        
        genai.configure(api_key=api_key)
        
        # Lista modelos dispon√≠veis para testar a key
        models = list(genai.list_models())
        if models:
            print("‚úÖ Gemini key v√°lida!")
            print(f"üìã Modelos dispon√≠veis: {len(models)}")
            return True
        else:
            print("‚ùå Gemini key inv√°lida ou sem modelos")
            return False
            
    except Exception as e:
        print(f"‚ùå Erro Gemini: {e}")
        return False


def test_litellm_integration():
    """Testa integra√ß√£o com LiteLLM."""
    try:
        import litellm
        
        provider = os.getenv("LLM_PROVIDER", "openai").lower()
        print(f"üß™ Testando LiteLLM com provider: {provider}")
        
        if provider == "openai":
            model = "gpt-3.5-turbo"
            api_key = os.getenv("OPENAI_API_KEY")
        elif provider == "groq":
            model = "groq/mixtral-8x7b-32768"
            api_key = os.getenv("GROQ_API_KEY")
        elif provider == "gemini":
            model = "gemini/gemini-pro"
            api_key = os.getenv("GOOGLE_API_KEY")
        else:
            print(f"‚ùå Provider {provider} n√£o suportado no teste")
            return False
            
        if not api_key:
            print(f"‚ùå API key n√£o encontrada para {provider}")
            return False
            
        # Configurar vari√°vel de ambiente para o provider
        if provider == "groq":
            os.environ["GROQ_API_KEY"] = api_key
        elif provider == "gemini":
            os.environ["GOOGLE_API_KEY"] = api_key
        elif provider == "openai":
            os.environ["OPENAI_API_KEY"] = api_key
            
        response = litellm.completion(
            model=model,
            messages=[{"role": "user", "content": "Hello"}],
            max_tokens=5
        )
        
        print("‚úÖ LiteLLM integra√ß√£o funcionando!")
        print(f"üìù Resposta: {response.choices[0].message.content}")
        return True
        
    except Exception as e:
        print(f"‚ùå Erro LiteLLM: {e}")
        return False


def main():
    """Executa todos os testes de API."""
    print("üöÄ Testando API Keys...\n")
    
    # Mostrar configura√ß√£o atual
    provider = os.getenv("LLM_PROVIDER", "openai")
    print(f"üìã Provider configurado: {provider}")
    print(f"üìã Arquivo .env carregado: {os.path.exists('.env')}\n")
    
    results = {}
    
    # Testar todas as keys
    print("=" * 50)
    print("TESTANDO APIS INDIVIDUAIS")
    print("=" * 50)
    
    results['openai'] = test_openai_key()
    print()
    
    results['groq'] = test_groq_key()
    print()
    
    results['gemini'] = test_gemini_key()
    print()
    
    print("=" * 50)
    print("TESTANDO INTEGRA√á√ÉO LITELLM")
    print("=" * 50)
    
    results['litellm'] = test_litellm_integration()
    print()
    
    # Resumo
    print("=" * 50)
    print("RESUMO DOS TESTES")
    print("=" * 50)
    
    for service, status in results.items():
        emoji = "‚úÖ" if status else "‚ùå"
        print(f"{emoji} {service.upper()}: {'OK' if status else 'FALHA'}")
    
    # Sugest√µes
    print("\n" + "=" * 50)
    print("SUGEST√ïES")
    print("=" * 50)
    
    if not any(results.values()):
        print("‚ö†Ô∏è  Nenhuma API key est√° funcionando!")
        print("1. Verifique se o arquivo .env est√° na raiz do projeto")
        print("2. Verifique se as keys est√£o corretas")
        print("3. Teste com curl/postman para confirmar")
    
    working_apis = [api for api, status in results.items() if status and api != 'litellm']
    if working_apis:
        print(f"üí° APIs funcionando: {', '.join(working_apis)}")
        print(f"üí° Configure LLM_PROVIDER para: {working_apis[0]}")
    
    return results


if __name__ == "__main__":
    main()